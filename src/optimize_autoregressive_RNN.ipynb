{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the Autoregressive RNN with continuous input\n",
    "- This model is autoregressive, which means that the prediction of the last time step is the input of the current time step. This way the model can predict a varying number of steps into the future without retraining\n",
    "- Some features, like time and weather, are fed into the model from outside even during prediction phase so the model does not have to predict those by itself\n",
    "\n",
    "Based on: https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_wind</th>\n",
       "      <th>prod_solar</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>solar_el</th>\n",
       "      <th>solar_el_clip</th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00+00:00</th>\n",
       "      <td>15498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.504006e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>-60.908284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.852558</td>\n",
       "      <td>15.288176</td>\n",
       "      <td>4.347648</td>\n",
       "      <td>-2.309275</td>\n",
       "      <td>-6.504426</td>\n",
       "      <td>1.835412</td>\n",
       "      <td>-2.912726</td>\n",
       "      <td>-1.002096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00+00:00</th>\n",
       "      <td>15406.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>-56.058615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.402722</td>\n",
       "      <td>14.609254</td>\n",
       "      <td>4.218358</td>\n",
       "      <td>-2.001596</td>\n",
       "      <td>-6.243442</td>\n",
       "      <td>1.721510</td>\n",
       "      <td>-3.024547</td>\n",
       "      <td>-1.148866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00+00:00</th>\n",
       "      <td>14922.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>-48.554986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.671664</td>\n",
       "      <td>14.329923</td>\n",
       "      <td>3.502013</td>\n",
       "      <td>-1.374882</td>\n",
       "      <td>-6.517594</td>\n",
       "      <td>1.778085</td>\n",
       "      <td>-2.993373</td>\n",
       "      <td>-1.056570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00+00:00</th>\n",
       "      <td>15022.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>-39.734647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.211067</td>\n",
       "      <td>13.624351</td>\n",
       "      <td>3.435171</td>\n",
       "      <td>-1.067060</td>\n",
       "      <td>-6.467290</td>\n",
       "      <td>1.582473</td>\n",
       "      <td>-3.276953</td>\n",
       "      <td>-1.139719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00+00:00</th>\n",
       "      <td>15234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013231</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>-30.400744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.712684</td>\n",
       "      <td>12.801144</td>\n",
       "      <td>3.789605</td>\n",
       "      <td>-1.089136</td>\n",
       "      <td>-6.811083</td>\n",
       "      <td>1.742942</td>\n",
       "      <td>-3.311717</td>\n",
       "      <td>-0.915913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           prod_wind  prod_solar       day_sin   day_cos  \\\n",
       "2017-01-01 00:00:00+00:00    15498.0         0.0  2.504006e-13  1.000000   \n",
       "2017-01-01 01:00:00+00:00    15406.9         0.0  2.588190e-01  0.965926   \n",
       "2017-01-01 02:00:00+00:00    14922.3         0.0  5.000000e-01  0.866025   \n",
       "2017-01-01 03:00:00+00:00    15022.0         0.0  7.071068e-01  0.707107   \n",
       "2017-01-01 04:00:00+00:00    15234.0         0.0  8.660254e-01  0.500000   \n",
       "\n",
       "                           year_sin  year_cos   solar_el  solar_el_clip  \\\n",
       "2017-01-01 00:00:00+00:00  0.010364  0.999946 -60.908284            0.0   \n",
       "2017-01-01 01:00:00+00:00  0.011081  0.999939 -56.058615            0.0   \n",
       "2017-01-01 02:00:00+00:00  0.011798  0.999930 -48.554986            0.0   \n",
       "2017-01-01 03:00:00+00:00  0.012515  0.999922 -39.734647            0.0   \n",
       "2017-01-01 04:00:00+00:00  0.013231  0.999912 -30.400744            0.0   \n",
       "\n",
       "                               pca_0      pca_1     pca_2     pca_3     pca_4  \\\n",
       "2017-01-01 00:00:00+00:00  -9.852558  15.288176  4.347648 -2.309275 -6.504426   \n",
       "2017-01-01 01:00:00+00:00 -10.402722  14.609254  4.218358 -2.001596 -6.243442   \n",
       "2017-01-01 02:00:00+00:00 -10.671664  14.329923  3.502013 -1.374882 -6.517594   \n",
       "2017-01-01 03:00:00+00:00 -11.211067  13.624351  3.435171 -1.067060 -6.467290   \n",
       "2017-01-01 04:00:00+00:00 -11.712684  12.801144  3.789605 -1.089136 -6.811083   \n",
       "\n",
       "                              pca_5     pca_6     pca_7  \n",
       "2017-01-01 00:00:00+00:00  1.835412 -2.912726 -1.002096  \n",
       "2017-01-01 01:00:00+00:00  1.721510 -3.024547 -1.148866  \n",
       "2017-01-01 02:00:00+00:00  1.778085 -2.993373 -1.056570  \n",
       "2017-01-01 03:00:00+00:00  1.582473 -3.276953 -1.139719  \n",
       "2017-01-01 04:00:00+00:00  1.742942 -3.311717 -0.915913  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..\\data\\prepared\\elec_time_pca-wx_combined.csv', parse_dates=['Unnamed: 0'], index_col=['Unnamed: 0'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "- 70% training\n",
    "- 20% validation\n",
    "- 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "n = len(df)\n",
    "df_train = df[0:int(n*0.7)]\n",
    "df_val = df[int(n*0.7):int(n*0.9)]\n",
    "df_test = df[int(n*0.9):]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler to training data\n",
    "scaler.fit(df_train)\n",
    "# scale all sets according to train set, preserve data frames\n",
    "df_train = pd.DataFrame(scaler.transform(df_train),\n",
    "                        columns=df.columns, index=df_train.index)\n",
    "df_val = pd.DataFrame(scaler.transform(df_val),\n",
    "                        columns=df.columns, index=df_val.index)\n",
    "df_test = pd.DataFrame(scaler.transform(df_test),\n",
    "                        columns=df.columns, index=df_test.index)\n",
    "\n",
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Windowing\n",
    "#### 1. Indexes and offsets\n",
    "\n",
    "- Windows Generator that can create multiple inputs, one for the inputs that are only known in the past (power production) and one for inputs that are also known in the future (time and weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, past_width, future_width,\n",
    "                 label_columns, precise_columns=None, forecast_columns=None,\n",
    "                 train_df=df_train, val_df=df_val, test_df=df_test):\n",
    "\n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Check if length of provided features match with data frame\n",
    "        num_columns = 0\n",
    "        num_columns += len(label_columns)\n",
    "        if precise_columns is not None:\n",
    "            num_columns += len(precise_columns)\n",
    "        if forecast_columns is not None:\n",
    "            num_columns += len(forecast_columns)\n",
    "        assert num_columns == len(train_df.columns), \\\n",
    "            \"Length of provided label, precise, and forecast features do not match data frame\"\n",
    "\n",
    "        # Work out the column indices\n",
    "        self.columns_indices = {name: i for i, name in\n",
    "                                enumerate(train_df.columns)}\n",
    "        self.label_columns = label_columns\n",
    "        self.label_columns_indices = {name: i for i, name in\n",
    "                                      enumerate(label_columns)}\n",
    "        self.precise_columns = precise_columns\n",
    "        self.forecast_columns = forecast_columns\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.past_width = past_width\n",
    "        self.future_width = future_width\n",
    "\n",
    "        self.total_window_size = past_width + future_width\n",
    "\n",
    "        self.input_past_slice = slice(0, past_width)\n",
    "        self.input_past_indices = np.arange(self.total_window_size)[\n",
    "            self.input_past_slice]\n",
    "\n",
    "        self.input_future_slice = slice(self.past_width, -1)\n",
    "        self.input_future_indices = np.arange(self.total_window_size)[\n",
    "            self.input_future_slice]\n",
    "\n",
    "        self.label_slice = slice(self.past_width, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[\n",
    "            self.label_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size:    {self.total_window_size}',\n",
    "            f'Input past indices:   {self.input_past_indices}',\n",
    "            f'Input future indices: {self.input_future_indices}',\n",
    "            f'Label indices:        {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "        # f'Precise column name(s):  {self.precise_columns}',\n",
    "        # f'Forecast column name(s): {self.forecast_columns}'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    # Past: All inputs are known\n",
    "    inputs_past = features[:, self.input_past_slice, :]\n",
    "\n",
    "    # Future: Only precise and forecast inputs are known\n",
    "    if self.precise_columns is None:\n",
    "        self.precise_columns = []\n",
    "    if self.forecast_columns is None:\n",
    "        self.forecast_columns = []\n",
    "    self.input_future_columns = self.precise_columns + self.forecast_columns\n",
    "\n",
    "    inputs_future = tf.stack(\n",
    "        [features[:, self.input_future_slice, self.columns_indices[name]]\n",
    "            for name in self.input_future_columns],\n",
    "        axis=-1)\n",
    "\n",
    "    labels = tf.stack(\n",
    "        [features[:, self.label_slice, self.columns_indices[name]]\n",
    "            for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "    # Slicing doesn't preserve static shape information, so set the shapes\n",
    "    # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "    inputs_past.set_shape([None, self.past_width, None])\n",
    "    inputs_future.set_shape([None, self.future_width-1, None])\n",
    "    labels.set_shape([None, self.future_width, None])\n",
    "\n",
    "    # Return inputs and labels\n",
    "    # The past and future input tuple will be unpacked in the model.call() method\n",
    "    return (inputs_past, inputs_future), labels\n",
    "\n",
    "\n",
    "WindowGenerator.split_window = split_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col=\"prod_solar\", max_subplots=3):\n",
    "    inputs, labels = self.example\n",
    "    (inputs_past, inputs_future) = inputs\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = self.columns_indices[plot_col]\n",
    "    max_n = min(max_subplots, len(inputs_past))\n",
    "    for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "\n",
    "        # Plot past inputs\n",
    "        plt.plot(self.input_past_indices, inputs_past[n, :, plot_col_index],\n",
    "                 label='Inputs', marker='.', zorder=3)\n",
    "\n",
    "        label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "\n",
    "        # Add last point of past array to future arrays to connect lines\n",
    "        label_indices_plot = np.insert(\n",
    "            self.label_indices, 0, self.input_past_indices[-1])\n",
    "        labels_plot = np.insert(\n",
    "            labels[n, :, label_col_index], 0, inputs_past[n, :, plot_col_index][-1])\n",
    "\n",
    "        # Plot labels\n",
    "        plt.plot(label_indices_plot, labels_plot,\n",
    "                 'C2', label='Labels', marker='.', zorder=1)\n",
    "\n",
    "        # Plot prediction\n",
    "        if model is not None:\n",
    "            predictions_plot = (model(inputs))[n, :, label_col_index]\n",
    "            predictions_plot = np.insert(\n",
    "                predictions_plot, 0, inputs_past[n, :, plot_col_index][-1])\n",
    "            plt.plot(label_indices_plot, predictions_plot,\n",
    "                     'C1', label='Predictions', marker='.', zorder=2)\n",
    "\n",
    "        # x Ticks every 6 hours\n",
    "        plt.xticks(np.arange(self.input_past_indices[0], self.label_indices[-1]+2, 6))\n",
    "\n",
    "        plt.ylabel(f'{plot_col} [normed]')\n",
    "        if n == 0:\n",
    "            plt.legend()\n",
    "\n",
    "    plt.xlabel('Time [h]')\n",
    "\n",
    "\n",
    "WindowGenerator.plot = plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create `tf.data.Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data, shuffle=True):\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        data=data,\n",
    "        targets=None,\n",
    "        sequence_length=self.total_window_size,\n",
    "        sequence_stride=1,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=32,)\n",
    "\n",
    "    ds = ds.map(self.split_window)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "    self._train = self.make_dataset(self.train_df)\n",
    "    return self._train\n",
    "\n",
    "# @train.setter\n",
    "# def train(self, value):\n",
    "#     self._train = value\n",
    "\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "    self._val = self.make_dataset(self.val_df)\n",
    "    return self._val\n",
    "\n",
    "# @val.setter\n",
    "# def val(self, value):\n",
    "#     self._val = value\n",
    "\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "    self._test = self.make_dataset(self.test_df)\n",
    "    return self._test\n",
    "\n",
    "# Setting of test property not allowed\n",
    "\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "        # No example batch was found, so get one from the `.test` dataset\n",
    "        result = next(iter(self.test))\n",
    "        # And cache it for next time\n",
    "        self._example = result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which features are only known for the past. These features will be predicted.\n",
    "prediction_features = ['prod_wind', 'prod_solar']\n",
    "num_predictions = len(prediction_features)\n",
    "\n",
    "# Choose which features are precisely known to the model at all time steps\n",
    "precise_features = ['day_sin', 'day_cos', 'year_sin',\n",
    "                    'year_cos', 'solar_el', 'solar_el_clip']\n",
    "\n",
    "# Choose which features are only imprecisely known to the model at future time steps\n",
    "# NOISE NOT YET IMPLEMENTED\n",
    "forecast_features = list(ae.columns)\n",
    "\n",
    "PAST_STEPS = 24\n",
    "PREDICTION_STEPS = 12\n",
    "\n",
    "window = WindowGenerator(\n",
    "    past_width=PAST_STEPS, future_width=PREDICTION_STEPS,\n",
    "    label_columns=prediction_features,\n",
    "    precise_columns=precise_features,\n",
    "    forecast_columns=forecast_features\n",
    ")\n",
    "\n",
    "window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `WindowGenerator` object gives access to the tf.data.Dataset objects, to easily iterate over the data.\n",
    "\n",
    "The `Dataset.element_spec` property tells the structure, data types, and shapes of the dataset elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.train.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over a `Dataset` yields concrete batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (example_inputs_past, example_inputs_future), example_labels in window.train.take(1):\n",
    "  print(f'Inputs past shape (batch, time, features): {example_inputs_past.shape}')\n",
    "  print(f'Inputs fut. shape (batch, time, features): {example_inputs_future.shape}')\n",
    "  print(f'Labels shape      (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an example window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.plot(plot_col=\"prod_solar\")\n",
    "# multi_window.plot(plot_col=\"prod_wind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive LSTM\n",
    "The model predicts individual time steps that are fed back into itself, so that the model can produce output with a varying length.\n",
    "This is implemented in the custom model class `AutoRegressiveRNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegressiveRNN(tf.keras.Model):\n",
    "    def __init__(self, units: list, out_steps: int, rnn_type=\"LSTM\"):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.type = rnn_type\n",
    "        self.rnn_cells = []\n",
    "        self.rnn_layers = []\n",
    "        if rnn_type == \"LSTM\":\n",
    "            for unit in self.units:\n",
    "                    self.rnn_cells.append(tf.keras.layers.LSTMCell(unit))\n",
    "        elif rnn_type == \"GRU\":\n",
    "            for unit in self.units:\n",
    "                    self.rnn_cells.append(tf.keras.layers.GRUCell(unit))\n",
    "        else:\n",
    "            raise AssertionError(\"Unknown type\")\n",
    "        # match rnn_type:\n",
    "        #     case \"LSTM\":\n",
    "        #         for unit in self.units:\n",
    "        #             self.rnn_cells.append(tf.keras.layers.LSTMCell(unit))\n",
    "        #     case \"GRU\":\n",
    "        #         for unit in self.units:\n",
    "        #             self.rnn_cells.append(tf.keras.layers.GRUCell(unit))\n",
    "        #     case other:\n",
    "        #         raise AssertionError(\"Unknown type\")\n",
    "        # Wrap the cells in an RNN to simplify the `warmup` method.\n",
    "        for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "            # If last layer: Do not return sequences\n",
    "            if i == len(self.rnn_cells)-1:\n",
    "                self.rnn_layers.append(tf.keras.layers.RNN(\n",
    "                    rnn_cell, return_sequences=False, return_state=True))\n",
    "            else:\n",
    "                self.rnn_layers.append(tf.keras.layers.RNN(\n",
    "                    rnn_cell, return_sequences=True, return_state=True))\n",
    "        self.dense = tf.keras.layers.Dense(num_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model warmup\n",
    "The warmup method initializes the model's internal state based on the full input from the past (power data, time and weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(self, x):\n",
    "    # inputs.shape => (batch, time, features)\n",
    "    # x.shape => (batch, lstm_units)\n",
    "    states = []\n",
    "    for rnn_layer in self.rnn_layers:\n",
    "        x, *state = rnn_layer(x)\n",
    "        states.append(state)\n",
    "    # predictions.shape => (batch, features)\n",
    "    prediction = self.dense(x)\n",
    "    return prediction, states\n",
    "\n",
    "\n",
    "AutoRegressiveRNN.warmup = warmup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model call\n",
    "A custom call is used to feed the model the full input from the past during warmup and then only the time and weather forecast during the prediction phase, where the model takes the prediction from the last time step to substitute the missing input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs, training=None):\n",
    "    # unpack the past and future inputs\n",
    "    inputs_past, inputs_future = inputs\n",
    "    # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "    predictions = []\n",
    "    # Past phase: Initialize the RNN state\n",
    "    prediction, states = self.warmup(inputs_past)\n",
    "    # Insert the first prediction.\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Future phase: Run the rest of the prediction steps\n",
    "    for n in range(self.out_steps-1):\n",
    "        # Select the known input at the current time step\n",
    "        input_future = inputs_future[:, n, :]\n",
    "        # Use the last prediction as unknown input and combine it with the known input\n",
    "        # x.shape => (batch, features)\n",
    "        x = tf.concat([prediction, input_future], axis=1)\n",
    "        # Execute one RNN step.\n",
    "        for i, rnn_cell in enumerate(self.rnn_cells):\n",
    "            x, states[i] = rnn_cell(x, states=states[i],\n",
    "                                    training=training)\n",
    "        # Convert the RNN output to a prediction.\n",
    "        prediction = self.dense(x)\n",
    "        # Add the prediction to the output.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # predictions.shape => (time, batch, features)\n",
    "    predictions = tf.stack(predictions)\n",
    "    # predictions.shape => (batch, time, features)\n",
    "    predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "AutoRegressiveRNN.call = call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics.r_square import RSquare\n",
    "import os\n",
    "\n",
    "\n",
    "def check_for_weights(model, checkpoint_dir):\n",
    "    # Restore latest model weights, if available\n",
    "    checkpoints = [checkpoint_dir + \"/\" +\n",
    "                   name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring weights from\", latest_checkpoint)\n",
    "        model.load_weights(latest_checkpoint)\n",
    "        return\n",
    "    print(\"No saved weights found\")\n",
    "    return\n",
    "\n",
    "\n",
    "def compile_and_fit(model, window, learning_rate, epochs=100, save=False, stop_early=True, model_name=None, patience=10, verbose='auto'):\n",
    "    callbacks = []\n",
    "    if save:\n",
    "        assert model_name is not None, \"No model name provided\"\n",
    "        # Prepare directory to save model\n",
    "        checkpoint_dir = '../models/'+model_name\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        # Load weights\n",
    "        \n",
    "        check_for_weights(model, checkpoint_dir)\n",
    "        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_dir + '/' + model_name + '_weights.h5',\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callbacks.append(model_checkpoint)\n",
    "\n",
    "    if stop_early:\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          patience=patience,\n",
    "                                                          mode='min',\n",
    "                                                          verbose=1,\n",
    "                                                          restore_best_weights=True)\n",
    "        callbacks.append(early_stopping)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate), metrics=['mae', tf.keras.metrics.RootMeanSquaredError(name='rmse'), RSquare()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=epochs,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=verbose)\n",
    "    return history\n",
    "\n",
    "\n",
    "val_performance = {}\n",
    "test_performance = {}\n",
    "history = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history['loss'], label='Training loss (MSE)')\n",
    "    plt.plot(history.history['val_loss'], label='Validation loss (MSE)')\n",
    "    # plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna as optuna\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "            'past_steps': trial.suggest_int(\"past_steps\",4,96),\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "              # number of layers\n",
    "              'n_layers': trial.suggest_int(\"n_layers\", 1, 3)\n",
    "              #'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    # vary number of past_steps\n",
    "    window = WindowGenerator(\n",
    "        past_width=params['past_steps'], future_width=PREDICTION_STEPS,\n",
    "        label_columns=prediction_features,\n",
    "        precise_columns=precise_features,\n",
    "        forecast_columns=forecast_features\n",
    "    )\n",
    "\n",
    "    # enable sampling of layers and units in each layer\n",
    "    units_list=[None] * params['n_layers']\n",
    "\n",
    "    for i in range(params['n_layers']):\n",
    "        # Suggest the number of units in each layer\n",
    "        n_units = trial.suggest_int(\"n_units_l{}\".format(i), 4, 32)\n",
    "        units_list[i]=n_units\n",
    "        \n",
    "        \n",
    "    # build model with giiven parametres\n",
    "    arlstm_model = AutoRegressiveRNN(units=units_list, out_steps=PREDICTION_STEPS, rnn_type=\"GRU\")\n",
    "    history = compile_and_fit(arlstm_model, window, epochs=50,learning_rate=params['learning_rate'], verbose=0)\n",
    "    \n",
    "    # get test performance as study criterion\n",
    "    test_performance = arlstm_model.evaluate(window.test, verbose=2)\n",
    "    \n",
    "            \n",
    "    # return the test_performance loss which is the first element\n",
    "    return test_performance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study hyperparameters\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save study and best values\n",
    "import joblib\n",
    "joblib.dump(study, '../optuna/study_arlstm_model.pkl')\n",
    "\n",
    "print('best_value:', study.best_value)\n",
    "with open('../optuna/best_trial_arlstm_model.txt', 'w') as f:\n",
    "    print(study.best_trial, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of hyperparameter optimization\n",
    "import kaleido\n",
    "import plotly\n",
    "\n",
    "fig = optuna.visualization.plot_parallel_coordinate(study, \n",
    "    params=['learning_rate', 'n_layers', 'past_steps']) \n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    font=dict(\n",
    "        family='serif',\n",
    "        size=10,\n",
    "    ))\n",
    "# save image\n",
    "fig.write_image('../reports/optuna_parallel_coordinates.jpg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buid NN with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = joblib.load('./optuna/study_Adam.pkl')\n",
    "\n",
    "# hyperparams['lr'] = study.best_params['learning rate']\n",
    "# hyperparams['betas'] = (study.best_params['beta1'], study.best_params['beta2']) # Adam\n",
    "# hyperparams['eps'] = study.best_params['epsilon']                               # Adam\n",
    "# # hyperparams['momentum'] = study.best_params['momentum']                         # SGD                               \n",
    "# hyperparams['weight_decay'] = study.best_params['weight decay']\n",
    "\n",
    "# # model_name = 'ARLSTM 32'\n",
    "# # history[model_name] = compile_and_fit(arlstm_model, window, model_name='ARLSTM32', verbose=2)\n",
    "# # # IPython.display.clear_output()\n",
    "\n",
    "# # val_performance[model_name] = arlstm_model.evaluate(window.val, verbose=0)\n",
    "# # test_performance[model_name] = arlstm_model.evaluate(window.test, verbose=1)\n",
    "\n",
    "# # window.plot(arlstm_model, plot_col=\"prod_wind\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e9655652794916721c836f64f0f2c40614fd3025e6f3f5246a082aecd982be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
