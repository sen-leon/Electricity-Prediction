\documentclass[11pt,table]{article}

\input{preamble}

\title{Project Title}
\author{Luis Gentner, Leon Sengün, Dilara Yildiz}
\date{\today}



\begin{document}
\begin{titlepage} 
	\centering 
	\rule{\textwidth}{1pt} 
	\vspace{2pt}\vspace{-\baselineskip} 
	\rule{\textwidth}{0.4pt} 
	\vspace{0.1\textheight} 
	
	
	%%% Adjust your project title here
	{\Huge PREDICTING RENEWABLE ENERGY }\\[0.5\baselineskip] 
	{\Huge PRODUCTION USING }\\[0.5\baselineskip]
	%{\Large }\\[0.5\baselineskip] 
	{\Huge MACHINE LEARNING METHODS} 
	
	
	\vspace{0.025\textheight} 
	\rule{0.3\textwidth}{0.4pt} 
	\vspace{0.1\textheight}
	
	%%% Your names, if long, a "\\" in between may help to make things look better
	{\Large \textsc{Luis Gentner, Leon Sengün, Dilara Yildiz}} 
	
	\vfill 
	
	%%% You can include a nice image from your project here
	\includegraphics[width=0.5\linewidth]{Figures/example_cover.png} \\
	\vspace{0.05\textheight}
	{\large\textsc{Machine Learning Methods in Mechanics \\Report}\\ -\\ University of Stuttgart} 
	
	
	\vspace{0.1\textheight} 
	
	%%% Adjust the date here if you like
	{\normalsize \today}
	
	
	\rule{\textwidth}{0.4pt}
	\vspace{2pt}\vspace{-\baselineskip}
	\rule{\textwidth}{1pt}
	
\end{titlepage}

\pagenumbering{roman}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

%%% The following structure is a suggestion
%%% If you prefer to use your own, you can change everything
\section{Introduction}

The increase in the share of renewable energy sources in total energy production leads to a increasingly fluctuating power generation. Therefore, measures for a stable energy supply will gain importance. Information about future energy production could enable power plant operators to control their power production up and down in order to match the incoming renewable energy. A future prediction could also help to store energy in a targeted manner. 
With this background, the goal of this work is to develop a machine learning model that predicts the renewable energy production 12 hours into the future.\\
There is a variety of model architectures for this problem, including CNNs (Convolutional Neural Networks), RNNs (Recurrent Neural Networks), Autoencoders, GRUs (Gated Recurrent Units) or LSTMs (Long Short Term Memory). This paper will first explore and evaluate existing models regarding their accuracy, then iteratively develop an advanced and optimized model architecture.\\

Description of the project. Images are always a plus. You should reference each figure in the text and explain what can be seen. The flow field shows particle velocities. It is taken from~\cite{Author2020}. What is the problem? What is the goal? What is your idea?\\ 

%\lipsum[2]

You can include wrapped figures and tables, like Table~\ref{tab:features}. To make it work, there should be no newlines between the wrapped table or figure and the surrounding text. Normal tables work just as usual, like in Table~\ref{tab:other_parameters}.\\
%\lipsum[1]

%\begin{wraptable}{r}{0.55\textwidth}
%	%\begin{table}[]
%	%\centering
%	%\vspace{0pt}
%	\begin{tabular}{@{} lrrrrrr @{}}
%		\toprule
%		 & $L$ & $\lambda^S$ & $\mu^S$ & $k_{0\text{S}}^{\text{F}1}$ & $k_{0\text{S}}^{\text{F}2}$ & $k_{0\text{S}}^{\text{F}3}$ \\
%		\midrule
%		min & 0.6 & 3.1 & 15.8 & 0.1 & 0.003 & 0.1 \\
%		max & 8.3 & 196.8 & 285.5 & 1.0 & 0.1 & 0.9 \\
%		example & 1.33 & 21 & 126 & 0.18 & 0.05 & 0.23 \\
%		\bottomrule
%	\end{tabular}
%	\caption{Feature values used for training the CNN.}\label{tab:features}
%\end{wraptable} 

%\lipsum[2-3]


%\begin{table}[]
%	\centering
%	%\vspace{0pt}
%	\begin{tabular}{@{} lrrrrrr @{}} 
%		\toprule
%		 & $L$ & $\lambda^S$ & $\mu^S$ & $k_{0\text{S}}^{\text{F}1}$ & $k_{0\text{S}}^{\text{F}2}$ & $k_{0\text{S}}^{\text{F}3}$ \\
%		\midrule
%		min & 0.6 & 3.1 & 15.8 & 0.1 & 0.003 & 0.1 \\
%		max & 8.3 & 196.8 & 285.5 & 1.0 & 0.1 & 0.9 \\
%		example & 1.33 & 21 & 126 & 0.18 & 0.05 & 0.23 \\
%		\bottomrule
%	\end{tabular}
%	\caption{Values used to create the simulation in Figure~\ref{fig:flow}.}\label{tab:other_parameters}
%\end{table}

\section{Data and Feature Engineering}
In order to predict future energy production from renewable sources, data showing energy production in recent years is needed. Old data sets are not representative because the number of solar and wind power plants in operation has increased significantly in recent years.(\textbf{Zitat}) Therefore, years 2017-2021 were selected for neural network training in this paper. \\
Future solar and wind energy generation depends not only on past energy generation, but also on weather conditions. To account for this, a second dataset of past-year weather information (2017-2021) was chosen as an optional additional input to the models.
The following data sets were used in this paper:

\begin{itemize}
  \item Electricity data (2017-2021) obtained from Energy-Charts (from Fraunhofer ISE), hourly resolution
  \item Weather data (2017-2021) from DWD (Deutscher Wetterdienst) including 468 meteorological stations in Germany, hourly resolution
\end{itemize}%

\subsection{Feature Engineering}
Raw data cannot necessarily be included directly as a feature in the model. Different pre-processing steps and a thoughtful selection of features can significantly improve the prediction. 
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.9]{Figures/electrData.png}
	\caption{Wind and solar energy production 2017-2021}
	\label{fig:electrData}
\end{figure}
Figure~\ref{fig:electrData} shows the wind and solar energy production of 2017-2021. Seasonal and daily fluctuations can be observed. These are further investigated with a fourier analysis, illustrated in figure~\ref{fig:fourier}.

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{Figures/fourierWind.png}
  \label{fig:fourierWind}
  \caption{Fourier analysis of wind energy production}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{Figures/fourierSolar.png}
  \label{fig:fourierSolar}
  \caption{Fourier analysis of solar energy production}
\end{subfigure}
\caption{Fourier analysis of electricity data}
\label{fig:fourier}
\end{figure}

The fourier analysis reveals, which frequencys appear in the given data. The solar energy production shows the highest peak at a frequency of 1/day, matching the daily elevation of the sun. For both, wind and solar energy the yearly (1/year) and daily (1/day) fluctuations are dominant.\\
To account for these two frequencies, time is mapped to sine and cosine functions representing the periodicity of year and day 
(Figure~\ref{fig:timeSignal}). 
In addition, the solar elevation is determined, which, as expected, correlates strongly with solar energy production. 
By truncating this solar elevation curve to zero, 
the lack of sunlight during night is represented
($=$\verb|solar_el_clip|).

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{Figures/timeSignal.png}
	\caption{Periodic features}
	\label{fig:timeSignal}
\end{figure}

The modified time features as well as air pressure, sunshine duration, temperature and wind speed were subjected to a correlation analysis. 
\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/correlation.png}
	\caption{Correlation analysis}
	\label{fig:correlation}
\end{figure}
Figure~\ref{fig:correlation} shows the correlation matrix. Darker colors indicate a higher (anti-)correlation. The solar energy production is strongly correlated to the cosine of the day, sunshine duration, temperature and clipped solar elevation. In contrast, wind energy production is only strongly correlated with wind speed and slightly correlated with pressure and temperature, which can be explained by the ideal gas equation. Although the sine of day and year do not hold a high correlation, they were included in the feature vector for completeness.\\

The final feature vector is a combination of 2 energy production features, 6 analytically determined time and solar elevation features, and 4 weather features (per weather station) as displayed in Table~\ref{tab:features}.

\begin{table}[H]
\begin{center}
\begin{tabular}{p{4.5cm}|p{5cm}|p{4.5cm}}
\toprule
\textbf{Energy Production} & \textbf{Time and Solar Elevation} & \textbf{Weather}              \\
\midrule
solar energy prod. & day sine                 & temperature          \\
wind energy prod.  & day cosine               & windspeed            \\
                   & year sine                & pressure             \\
                   & year cosine              & sunshine duration    \\
                   & solar elevation          &                      \\
                   & clipped solar elevation  &                     \\ \bottomrule
\end{tabular}
\end{center}
\caption{Features}
\label{tab:features}
\end{table}

Out of 468 meteorological stations in Germany, only 117 provide reliable data for the years 2017-2021. Of these remaining stations, 12 were selected for further representation of German weather. Decisive for the selection was the spatial proximity to offshore and solar installations as well as a broad distribution across Germany. The final weather stations are illustrated in figure~\ref{fig:weatherStations}.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{Figures/weatherStations.png}
	\caption{Selected weather stations in Germany}
	\label{fig:weatherStations}
\end{figure}

\section{Methods and Model Architectures}

The goal of this work is to predict solar and wind energy production 12 hours into the future. Current research offers a variety of machine learning models for this problem. Therefore, as a first step, different models were applied to the problem and evaluated regarding their prediction accuracy. Unpromising approaches were then discarded while succesful models were further explored and improved. The R$^2$ score was used as a measure of the accuracy of the prediction.

The following models were investigated:

\begin{itemize}
\item \textbf{Repeat last Step:} This model only repeats the last given timestep, leading to a constant solar and wind energy production level in the future. 
%As expected the model shows poor results. 
\item \textbf{Repeat Yesterday:} Here the course of yesterday, starting at the same time, is repeated. 
\item \textbf{Linear:} This architecture depicts a linear relation inducing a higher accuracy.
\item \textbf{Dense Layer:} While the first three models did not use any machine learning techniques, this architecture uses 512 neurons in a dense layer. 
\item \textbf{CNN:} Convolutional Neural Network with 3x256 and 25x256
\item \textbf{SRNN:} Simple Recurrent Neural Network with 32 units. RNNs are specialized for time series.
\item \textbf{GRU:} Gated Recurrent Units with 32 units, an improved version of RNNs. 
\item \textbf{LSTM 32:} Long Short Term Memory network with 32 units, advanced version of RNNs.
\item \textbf{LSTM 32$^2$:} Long Short Term Memory network with two layers each containing 32 units.
\end{itemize}


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{Figures/benchmarks.png}
	\caption{Iterative model development}
	\label{fig:benchmarks}
\end{figure} 

Figure \ref{fig:benchmarks} shows the R$^2$ scores, that were reached by the different models. Since the models 
``Repeat last Step'' and 
``Repeat Yesterday''
only copy existing energy production values, their performance is very low (R$^2$>0.5). While the linear model still shows low accuracy, neural network approaches reached scores over 0.8. Recurrent neural networks perform better, because they are specialized for time series. GRUs and LSTMs are on par. Since GRUs are less complex in structure and thus require shorter training times, they were selected as the basis for further model development.

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/modelEvolution.png}
	\caption{Iterative model development}
	\label{fig:modelEvo}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/SRNN.png}
	\caption{Simple recurrent neural network (SRNN)}
	\label{fig:SRNN}
\end{figure}
Single-shot RNNs are the simplest recurrent neural networks. After the Warmup-phase, they predict a predefined number of future steps at once. Although they depict the temporal dependancies in time series, their structure does not allow to vary the length of the prediction output without retraining.
\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/ARNN.png}
	\caption{Autoregressive recurrent neural network (ARNN)}
	\label{fig:ARNN}
\end{figure}
Autoregressive neural networks work differently: After the Warmup-phase, the prediction of each unit is used as input for the next time step. This iterative architecture enables a flexible output length without retraining.\\

One disadvantage of the given models is that they do not take into account future information. For example, even though time and solar elevation are known for the future, they cannot be included in the model due to their given architectures.

Hence a new model architecture, an ARNN with continous input, was developed. The idea was to not only include time and solar elevation, but also weather forecasts in the future inputs. The model is structured as follows: During the Warmup-phase the recurrent units are fed with power, weather, and time data. Then, when the prediction starts, the recurrent units do not only pass the output of the last cell to the next, but also additional future inputs including weather and time data.
 
\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/continousARNN.png}
	\caption{Continous autoregressive recurrent neural network}
	\label{fig:continousARNN}
\end{figure}

The continous ARNN was realized with both GRUs and LSTMs. Different numbers of layers and units were investigated. The maximum R$^2$-score obtained is 0.93. For better results, the information density of the input data must be further improved. One possibility is to use more than 12 weather stations. To prevent an overloaded feature vector, the idea is to increase the feature density. Therefore, two approaches were tested: Feature compression by a partial component analysis (PCA) and with an encoder.\\
\textbf{Encoder:}
In order to check the quality of the compression, an autoencoder was created in a first step to show whether the real weather data can be transformed backwards from the compressed data. A compression with 48 components showed adequate results. ----- wehich accuracy????\\
\textbf{PCA:}
A linear PCA was used and the number of components was reduced to eight.\\
Although the PCA can only model linear relationships and includes eight features, its performance is on par with that of the more complex encoder. Therefore, it was used as the final model:
\begin{itemize}
\item Deep autoregressive GRU with continous input
\item 3 layers [32, 32, 32]
\item Inputs (24 time steps):
\begin{itemize}
\item Solar and wind energy production (during past/warmup phase)
\item 8 time and sun elevation features
\item 8 PCA reduced weather features
\end{itemize}
\item Prediction of 12 time steps 
\end{itemize}

To further improve the prediction accuracy of the final model, hyperparameter optimization was performed. Due to Tensorflow incompatibilities on the institute server, the optimization was run on low-level hardware. This issue limited the number of possible optimization trials to 25. Optuna, an open source hyperparameter optimization framework was used to optimize the following three hyperparameters: 
\begin{itemize}
\item Learning rate
\item Units per layer
\item Past input steps
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/optimImportance.png}
	\caption{Continous autoregressive recurrent neural network}
	\label{fig:continousARNN}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[scale=1]{Figures/optimHistory.png}
	\caption{Continous autoregressive recurrent neural network}
	\label{fig:continousARNN}
\end{figure}

\section{Results}

\begin{figure}[H]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{Figures/solarResults.png}
  \label{fig:fourierWind}
  \caption{Results of solar energy prediction}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=0.9\linewidth]{Figures/windResults.png}
  \label{fig:fourierSolar}
  \caption{Results of wind energy prediction}
\end{subfigure}
\caption{Solar and wind energy production with final model}
\label{fig:fourier}
\end{figure}

\section{Conclusion}
\section{Outlook}
Account for weather forecast inaccuracy:
Train with real forecast data
Distort weather data: Random walk?
CNN Auto-encoder: Detect spatial relationships
Employ statistic methods
e.g structural time series




%\begin{wrapfigure}{r}{0.55\textwidth}
%	\centering
%	\includegraphics[scale=1.0]{Figures/example_cover.png}
%	\caption{You can also use wrapped figures like this.}
%	\label{fig:wrapfigure_example}
%\end{wrapfigure}

\begin{footnotesize}
\bibliographystyle{acm}


%%% This builds the bibliography
%%% You can use either bibtex with the following line and the "bibliography.bib" file
%%% OR ALTERNATIVELY comment the next line and uncomment the "thebibliography" environment

\bibliography{bibliography}

%%% comment the line above and uncomment the lines below
%%% for manually creating the bibliography

%\begin{thebibliography}{1}
%	
%	\bibitem{Author2020}% 
%	\textsc{A.\,W.~Harrow, A.~Hassidim, and S.~Lloyd},
%	\emph{Physical review letters 113} (15), 150502, (2009)
%	
%	\bibitem{Author2012}% 
%	\textsc{A.\,Y.~Kitaev},
%	\emph{Russian Mathematical Surveys 52} (6) p.\,1191--1249, (1997)
%	
%	
%\end{thebibliography}


\end{footnotesize}


%\newpage

\end{document}
